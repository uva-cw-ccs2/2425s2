{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff69739",
   "metadata": {},
   "source": [
    "# **Group Coding Exercise: Exploring Text Processing and Word Importance**\n",
    "\n",
    "## **Objective**\n",
    "In this exercise, you'll work in small groups to analyze how different text-processing techniques (n-grams, stemming, lemmatization, and TF-IDF) influence the most important words in a dataset. You'll then visualize the results using word clouds and share your findings via Mentimeter.\n",
    "\n",
    "## **Setup Instructions**\n",
    "1. Install required libraries if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d502a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "   pip install nltk sklearn wordcloud matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9f04af",
   "metadata": {},
   "source": [
    "2. Import necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b1a385",
   "metadata": {},
   "outputs": [],
   "source": [
    "   import nltk\n",
    "   from nltk.tokenize import word_tokenize\n",
    "   from nltk.corpus import stopwords\n",
    "   from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "   from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "   from wordcloud import WordCloud\n",
    "   import matplotlib.pyplot as plt\n",
    "   import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c074f",
   "metadata": {},
   "source": [
    "\n",
    "## **Step 1: Group Assignments**\n",
    "Each group will focus on a different text-processing technique.\n",
    "\n",
    "- **Group 1:** Tokenization & stopword removal\n",
    "- **Group 2:** Stemming\n",
    "- **Group 3:** Lemmatization\n",
    "- **Group 4:** N-grams (bigrams or trigrams)\n",
    "\n",
    "## **Step 2: Load a sample dataset**\n",
    "Use a small dataset like product reviews, news headlines, or tweets. Hereâ€™s an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7645554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Natural Language Processing is amazing!\",\n",
    "    \"I love exploring text analytics and data science.\",\n",
    "    \"TF-IDF helps identify important words in documents.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260bdead",
   "metadata": {},
   "source": [
    "\n",
    "## **Step 3: Text Processing Techniques**\n",
    "### **Group 1: Tokenization & Stopword Removal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ac3777",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    return ' '.join([word for word in words if word.isalnum() and word not in stop_words])\n",
    "\n",
    "processed_text = [preprocess_text(text) for text in sample_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d5cb98",
   "metadata": {},
   "source": [
    "\n",
    "### **Group 2: Stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2700ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_text(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    return ' '.join([stemmer.stem(word) for word in words if word.isalnum()])\n",
    "\n",
    "stemmed_text = [stem_text(text) for text in sample_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6726c2e0",
   "metadata": {},
   "source": [
    "\n",
    "### **Group 3: Lemmatization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e27bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in words if word.isalnum()])\n",
    "\n",
    "lemmatized_text = [lemmatize_text(text) for text in sample_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35122845",
   "metadata": {},
   "source": [
    "\n",
    "### **Group 4: N-Grams & TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9867592",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(2,2))  # Change to (3,3) for trigrams\n",
    "tfidf_matrix = vectorizer.fit_transform(sample_text)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "importance = np.array(tfidf_matrix.sum(axis=0)).flatten()\n",
    "top_ngrams = sorted(zip(feature_names, importance), key=lambda x: -x[1])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542b91c9",
   "metadata": {},
   "source": [
    "\n",
    "## **Step 4: Generate Word Clouds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wordcloud(text_list, title):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(text_list))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "generate_wordcloud(processed_text, \"Tokenization & Stopword Removal\")\n",
    "generate_wordcloud(stemmed_text, \"Stemming\")\n",
    "generate_wordcloud(lemmatized_text, \"Lemmatization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc42c91",
   "metadata": {},
   "source": [
    "\n",
    "## **Step 5: Share & Discuss**\n",
    "1. Save your generated word cloud as an image, like: `wordcloud.to_file(\"wordcloud.png\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e70d002",
   "metadata": {},
   "source": [
    "2. Upload it [here](https://amsuni-my.sharepoint.com/:f:/g/personal/a_c_kroon_uva_nl/EtGTToswpF5GtpUu20lCQU8B6Rqe_e3x_uU_pkq3tFoyMg?e=XkOq4Q).\n",
    "3. Compare different word clouds and discuss:\n",
    "   - How does preprocessing change the key words?\n",
    "   - Do n-grams reveal different insights than single words?\n",
    "   - What do TF-IDF scores tell us about word importance?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
