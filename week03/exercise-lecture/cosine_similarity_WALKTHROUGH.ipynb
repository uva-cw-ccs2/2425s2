{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de884881",
   "metadata": {},
   "source": [
    "# ðŸŽ¬ Movie plot similarity explorer\n",
    "\n",
    "This notebook helps you understand **text similarity** by comparing movie plot descriptions. It is a *walkthrough* notebook; hence, it is not an assignment but serves to illustrate how this works!\n",
    "\n",
    "We will:\n",
    "- Use **CountVectorizer** and **TfidfVectorizer** with cosine similarity\n",
    "- Use **spaCy embeddings** for a smarter similarity (soft cosine)\n",
    "- Take a **user query** and find the most similar movie plot\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e03acf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/Users/anne/Library/Caches/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting en-core-web-md==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.8.0\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "# Only run this once to install the model\n",
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eef9c16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/anne/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0572343e-cbcb-4246-8b66-5e77db2166af",
   "metadata": {},
   "source": [
    "## Define movie plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f6ce9f5",
   "metadata": {},
   "outputs": [],
   "source": [
"movie_plots = [\n",
"    \"A man discovers where reality is an illusion and he joins a resistance to fight a digital overlords. (The Matrix)\",\n",
"    \"An exiled heir returns to take back his homeland from a tyrant uncle. (The Lion King)\",\n",
"    \"A young couple from different worlds fall in love aboard a doomed ship. (Titanic)\",\n",
"    \"A group undertakes a journey to destroy a powerful object and defeat a rising darkness. (The Lord of the Rings)\",\n",
"    \"A young orphan is invited to a hidden institution to learn to harness mystical forces. (Harry Potter)\",\n",
"    \"A man wakes up with no memory and evades secret agents while uncovering his past. (The Bourne Identity)\",\n",
"    \"A linguist must interpret an alien language to prevent global war. (Arrival)\",\n",
"    \"A baseball manager uses data and algorithms to rebuild his losing team. (Moneyball)\",\n",
"    \"A student builds a tech empire while navigating betrayal and lawsuits. (The Social Network)\",\n",
"    \"A lonely man falls in love with an intelligent operating system. (Her)\"\n",
"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1157ae6c-480d-49d3-a664-23c57fe1a0a8",
   "metadata": {},
   "source": [
    "## You can explore/ play around with regular and soft cosine with this dataset [here](https://moviesimilarity-guvj2z7bwubdlxkibnn7e3.streamlit.app/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f667b8e4",
   "metadata": {},
   "source": [
    "### ðŸ” Enter your own plot/query\n",
    "Type a short movie description or idea, and we'll show the most similar movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1068bf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User query\n",
    "query_plot = \"Boy finds school for magic, where he was taught how to control powerful spells and faces dark force.\"\n",
    "all_texts = movie_plots + [query]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bf36d8",
   "metadata": {},
   "source": [
    "## Cosine Similarity based on CountVectorizer\n",
    "This just looks at word overlap, not meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83779444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Similar Movie:\n",
      "Movie 10: A young man moves to a new city where he is invited for a job and tries to balance her personal and professional life. (The New Beginnings)\n",
      "Similarity Score: 0.4082\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectors = vectorizer.fit_transform([query_plot] + movie_plots)\n",
    "cosine_sim = cosine_similarity(vectors[0:1], vectors[1:])\n",
    "#print(\"CountVectorizer Cosine Similarities:\", cosine_sim)\n",
    "\n",
    "# Find the index of the most similar movie\n",
    "most_similar_index = cosine_sim[0].argmax()\n",
    "most_similar_score = cosine_sim[0][most_similar_index]\n",
    "\n",
    "# Output the best match\n",
    "print(\"ðŸŽ¯ Most Similar Movie:\")\n",
    "print(f\"Movie {most_similar_index}: {movie_plots[most_similar_index]}\")\n",
    "print(f\"Similarity Score: {most_similar_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b1398ac-7a8d-4ea6-9e28-37ac780cbc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie 0: A man discovers reality is an illusion and joins a resistance to fight digital overlords. (The Matrix)\n",
      "Similarity Score: 0.2309\n",
      "------\n",
      "Movie 1: An exiled heir returns to take back his homeland from a tyrant uncle. (The Lion King)\n",
      "Similarity Score: 0.1155\n",
      "------\n",
      "Movie 2: A young couple from different worlds fall in love aboard a doomed ship. (Titanic)\n",
      "Similarity Score: 0.0000\n",
      "------\n",
      "Movie 3: A group undertakes a journey to destroy a powerful object and defeat a rising darkness. (The Lord of the Rings)\n",
      "Similarity Score: 0.2108\n",
      "------\n",
      "Movie 4: A young orphan is invited to a hidden institution where he learns to harness mystical forces. (Harry Potter)\n",
      "Similarity Score: 0.3689\n",
      "------\n",
      "Movie 5: A man wakes up with no memory and evades secret agents while uncovering his past. (The Bourne Identity)\n",
      "Similarity Score: 0.0542\n",
      "------\n",
      "Movie 6: A linguist must interpret an alien language to prevent global war. (Arrival)\n",
      "Similarity Score: 0.1348\n",
      "------\n",
      "Movie 7: A baseball manager uses data and algorithms to rebuild his losing team. (Moneyball)\n",
      "Similarity Score: 0.1936\n",
      "------\n",
      "Movie 8: A student builds a tech empire while navigating betrayal and lawsuits. (The Social Network)\n",
      "Similarity Score: 0.0645\n",
      "------\n",
      "Movie 9: A lonely man falls in love with an intelligent operating system. (Her)\n",
      "Similarity Score: 0.0000\n",
      "------\n",
      "Movie 10: A young man moves to a new city where he is invited for a job and tries to balance her personal and professional life. (The New Beginnings)\n",
      "Similarity Score: 0.4082\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "## Whant to know the cosine scores of the other movies? \n",
    "for idx, score in enumerate(cosine_sim[0]):\n",
    "    print(f\"Movie {idx}: {movie_plots[idx]}\")\n",
    "    print(f\"Similarity Score: {score:.4f}\")\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a7643b",
   "metadata": {},
   "source": [
    "## Cosine similarity using TF-IDF\n",
    "This gives more importance to important words, less to common words like \"the\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91489cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Similar Movie:\n",
      "Movie 10: A young man moves to a new city where he is invited for a job and tries to balance her personal and professional life. (The New Beginnings)\n",
      "Similarity Score: 0.2238\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf_vectors = tfidf.fit_transform([query_plot] + movie_plots)\n",
    "tfidf_sim = cosine_similarity(tfidf_vectors[0:1], tfidf_vectors[1:])\n",
    "#print(\"TF-IDF Cosine Similarities:\", tfidf_sim)\n",
    "# Find the index of the most similar movie\n",
    "most_similar_index = tfidf_sim[0].argmax()\n",
    "most_similar_score = tfidf_sim[0][most_similar_index]\n",
    "\n",
    "# Output the best match\n",
    "print(\"ðŸŽ¯ Most Similar Movie:\")\n",
    "print(f\"Movie {most_similar_index}: {movie_plots[most_similar_index]}\")\n",
    "print(f\"Similarity Score: {most_similar_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77766b72",
   "metadata": {},
   "source": [
    "## Soft Cosine similarity (using embeddings from spaCy)\n",
    "This is the smartest method. It uses word vectors to compare meaning.\n",
    "It knows \"wizard\" and \"magic\" are related, even if not identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7a1b6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Most Similar Movie:\n",
      "Movie 4: A young orphan is invited to a hidden institution where he learns to harness mystical forces. (Harry Potter)\n",
      "Similarity Score: 0.9142\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "query_doc = nlp(query_plot)\n",
    "similarities = [query_doc.similarity(nlp(p)) for p in movie_plots]\n",
    "#print(\"spaCy Similarities:\", similarities)\n",
    "\n",
    "# Find the index of the most similar plot\n",
    "most_similar_index = similarities.index(max(similarities))\n",
    "most_similar_score = similarities[most_similar_index]\n",
    "\n",
    "# Output the best match\n",
    "print(\"Most Similar Movie:\")\n",
    "print(f\"Movie {most_similar_index}: {movie_plots[most_similar_index]}\")\n",
    "print(f\"Similarity Score: {most_similar_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813d708a-8758-45de-8051-81f07fda1f58",
   "metadata": {},
   "source": [
    "# Add preprocessing to the mix!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607fbd9e-eb44-442c-aee6-62d72c870b59",
   "metadata": {},
   "source": [
    "### In a next step, you can investigate how cosine similiary scores differ after applying preprocessing steps.\n",
    "\n",
    "## Why can preprocessing improves cosine similarity?\n",
    "\n",
    "When comparing text similarity using vectorizers like `CountVectorizer` or `TfidfVectorizer`, **preprocessing the text** can significantly improve the results. Here's why:\n",
    "\n",
    "### What Preprocessing Does\n",
    "\n",
    "| Preprocessing Step     | Purpose |\n",
    "|------------------------|---------|\n",
    "| **Lowercasing**        | Makes \"The\" and \"the\" identical |\n",
    "| **Tokenization**       | Breaks text into words for further processing |\n",
    "| **Stopword Removal**   | Removes common, non-informative words like \"the\", \"is\", etc. |\n",
    "| **Stemming**           | Reduces words to their root form (e.g., \"loved\" â†’ \"love\") |\n",
    "\n",
    "### How this helps cosine similarity\n",
    "\n",
    "Cosine similarity measures the **angle between two vectors** â€” not their length. Cleaned and normalized vectors are:\n",
    "- More compact\n",
    "- Less noisy\n",
    "- More focused on the meaningful content words\n",
    "\n",
    "This leads to **more accurate similarity comparisons** between texts.\n",
    "\n",
    "For example:\n",
    "Raw: \"The movie is amazing!\" Cleaned: \"movi amaz\"\n",
    "Both \"The movie is amazing!\" and \"An amazing movie indeed.\" will reduce to something like `[\"movi\", \"amaz\"]`, making them more likely to match.\n",
    "\n",
    "---\n",
    "\n",
    "### When NOT to preprocess\n",
    "\n",
    "When using embeddings (for Soft Cosine), extensive preprocessing, like stemming or stopword removal, is not needed!\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "> Use basic preprocessing (lowercasing, punctuation removal, stopword removal, stemming) when working with `CountVectorizer` or `TfidfVectorizer` for better cosine similarity -- but not when using `spacy Embeddings` for soft cosine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9ea5d0eb-dabf-4410-9612-5aff5c8aa257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Stem the tokens\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
    "    \n",
    "    return stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "007337bd-378f-475e-a51c-ed540c7e104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess plots\n",
    "processed_plots = [preprocess_text(text) for text in movie_plots]\n",
    "processed_query = preprocess_text(query_plot)\n",
    "\n",
    "# Join tokens back into strings (otherwise you will get errors when trying to vectorize your text)\n",
    "processed_plots_joined = [' '.join(tokens) for tokens in processed_plots]\n",
    "processed_query_joined = ' '.join(processed_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f7920df-a3c1-4acd-a12d-f64904b066fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now, lets use the cleaned text to cacluate cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a8a582fd-532c-4e12-9f4b-bdba0412abb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Most Similar Movie:\n",
      "Movie 3: A group undertakes a journey to destroy a powerful object and defeat a rising darkness. (The Lord of the Rings)\n",
      "Similarity Score: 0.1818\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "#vectorizer = TfidfVectorizer() # or use tfidf\n",
    "vectors = vectorizer.fit_transform([processed_query_joined] + processed_plots_joined)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_sim = cosine_similarity(vectors[0:1], vectors[1:])\n",
    "\n",
    "# Find the most similar movie\n",
    "most_similar_index = cosine_sim[0].argmax()\n",
    "most_similar_score = cosine_sim[0][most_similar_index]\n",
    "\n",
    "# Output the result\n",
    "print(\"ðŸŽ¯ Most Similar Movie:\")\n",
    "print(f\"Movie {most_similar_index}: {movie_plots[most_similar_index]}\")\n",
    "print(f\"Similarity Score: {most_similar_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
