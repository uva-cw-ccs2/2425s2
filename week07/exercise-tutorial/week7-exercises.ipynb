{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecb0e531",
   "metadata": {},
   "source": [
    "# Getting some hands-on experience with supervised machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f47b20",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "In this tutorial you will work with supervised machine learning. We will classify tweets into four categories namely: `normal`, `abusive`, `hateful`, and `spam`.\n",
    "\n",
    "As you noted when reading the literature assigned for this and last week, there are a few steps that we need to take before we can use supervised machine learning. Namely:\n",
    "* Collect data (in CS often texts, e.g., tweets)\n",
    "* Develop a codebook and hand-code the data\n",
    "\n",
    "In this tutorial, we focus on the actual machine learning part of the process. Hence, we will use a dataset that already has been coded by humans. It contains tweets and each tweet has a label indicating to which of four categories it belongs, namely normal, abusive, hateful, or spam. Hence, we skip the first two steps of the process described above.\n",
    "\n",
    "Download the data for this exercise named \"hatespeech_text_label_vote_RESTRICTED_100K.csv\". These datafiles were retrieved from: https://www.dropbox.com/sh/4mapojr85a6sc76/AABYMkjLVG-HhueAgd0qM9kwa?dl=0\n",
    "\n",
    "Using the examples from past lectures, can you write a script that opens each file and:\n",
    "* Creates one list with the tweets\n",
    "* Creates one list with the labels of the tweets\n",
    "\n",
    "What could you do to check that this process went well? Can you explore the data a bit (i.e., by checking how often each label is present in the different datasets)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2112676",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Now that we have read in the data, we will proceed to the next step: Splitting our data into a training set and a test set. Luckily, scikit-learn has a function that can do so for us! Run the code presented in the next block to split up the dataset.\n",
    "        \n",
    "* What do these lines of code do?\n",
    "* Do you know what the random_state part refers to? Why is this useful?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b45e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tweets_train, tweets_test, y_train, y_test = train_test_split(tweets, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff085196",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "On to the next step: Transforming the text into numbers, or setting up a vectorizer. Can you create some code that uses a count vectorizer on the texts that you read in? Hint: check out the example provided in the slides of previous weeks! Doing so, you will see that the stopwords are defined (as a built-in stop word list). Why is that done?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e30d61e",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Now, let’s train a classifier and run it on the test data! Can you use the examples this week's lecture to train a Naïve Bayes classifer with our count vectorizer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177430c6",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "When you run the code you created for the previous question, you will see that it prints no output. How do you know if your code worked? Run the code presented in the next block (depending on how you named your labels, you may need to adjust the arguments).\n",
    "\n",
    "Check out the documentation of the scikit learn package: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "\n",
    "What do the numbers in the output mean? What can you do with it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eb3389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(y_pred[:10])\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d97751",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Our last classifier was based on a count vectorizer using Naïve Bayes. Can you now train another classifier based on `Logistic Regression` and a `tf-idf vectorizer`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09fe6a2",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "As you saw in the article by Meppelink et al. (2021), we can try different combinations of these models (Naïve Bayes and Logistic Regression) and vectorizers (count and tf-idf). If you want to use Naïve Bayes and Logistic Regression as the models for a classifier, and a count vectorizer and a tf-idf vectorizer, how many classifiers could you then train? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e29260",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "\n",
    "If we want to train multiple different classifiers, we could simply copy-paste the code used in the previous questions and adjust it for each of the classifiers. However, a cleaner approach is to write a function in which we define the specifics of each classifier. The code below does that.\n",
    "\n",
    "In this code, we create a loop that trains each classifier by calling the function that is built in the first part of the code. \n",
    "\n",
    "Run the code below and compare it to the code that you wrote to train one classifier: Do you understand what is happening there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09348f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "configs = [\n",
    "    (\"NB-count\", CountVectorizer(min_df=5, max_df=.5), MultinomialNB()),\n",
    "    (\"NB-TfIdf\", TfidfVectorizer(min_df=5, max_df=.5), MultinomialNB()),\n",
    "    (\"LR-Count\", CountVectorizer(min_df=5, max_df=.5), LogisticRegression(solver=\"liblinear\")),\n",
    "    (\"LR-TfIdf\", TfidfVectorizer(min_df=5, max_df=.5), LogisticRegression(solver=\"liblinear\"))\n",
    "]\n",
    "\n",
    "for name, vectorizer, classifier in configs:\n",
    "    print(name)\n",
    "    X_train = vectorizer.fit_transform(tweets_train)\n",
    "    X_test = vectorizer.transform(tweets_test)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86c8380",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "\n",
    "Check out the documentation of scikit learn (https://scikit-learn.org/stable/supervised_learning.html). Can you try to use other models and train a classifier with them? Can you merge this code into the code used in the previous question?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf209f7e",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "\n",
    "Based on the output that the classifier prints, what classifier performs the best? In your answer, consider:\n",
    "* What information you need to identify the best classifier\n",
    "* What metric you base your conclusion (i.e., precision, recall, accurcay, or F1-score) on and why"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977fce73",
   "metadata": {},
   "source": [
    "## Question 11\n",
    "\n",
    "Let's say that you base your evaluation on the F1-score of the classifier. You can choose between the macro average and the weighted average of the F1-score. Check out the scikit learn documentation (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html). What F1-value (macro average or weighted average) would you select?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92830270",
   "metadata": {},
   "source": [
    "## Question 12\n",
    "\n",
    "When looking at the classification report, you will see another column indicating values for something labelled 'support'.\n",
    "Can you do some searching online and find out what 'support' is?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afe8fa3",
   "metadata": {},
   "source": [
    "## Question 13\n",
    "\n",
    "Two researchers want to use the classifier to distinguish between tweets that are spam or hateful and tweets that are not (either because they are normal or abusive). \n",
    "They are, however, not happy with the performance of the classifier when looking at the accuracy, precision, and recall for the spam category or the hateful category.\n",
    "One of the researchers suggests to first recode the labels, so that all tweets that were annotated as spam receive a label 'spam' or 'hateful' are grouped together and all other tweets are grouped together as well.\n",
    "\n",
    "What would the consequences be of doing so? What can you do to check your own answer? Try to recode the labels and see what happens!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80781bc5",
   "metadata": {},
   "source": [
    "## Question 14\n",
    "\n",
    "For now, let's say that the classifier based on a count vectorizer and Logistic Regression is the one we prefer. We now want to use this model to predict the label for new data that we have not annotated (remember, this was the whole goal of SML)!\n",
    "\n",
    "To do this, let’s save our classifier and our vectorizer to a file. If we don’t do this, we would need to re-train our model every time we want to use it. This is not so convenient, for example, we would always need to have our training data at hand. The code below shows you how to make a vectorizer and train a classifier (a repetition of what we did before to show you the whole process) and store them into a file.\n",
    "\n",
    "In the code, you will see that both the classifier and the vectorizer are stored into a file. Why do you need to store both (why not just store the classifier only)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858d4a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# Make a vectorizer and train a classifier\n",
    "vectorizer=CountVectorizer(min_df=5, max_df=.5)\n",
    "classifier=LogisticRegression(solver=\"liblinear\")\n",
    "X_train=vectorizer.fit_transform(tweets_train)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Save them to disk\n",
    "with open(\"myvectorizer.pkl\",mode=\"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "with open(\"myclassifier.pkl\",mode=\"wb\") as f:\n",
    "    joblib.dump(classifier, f)\n",
    "\n",
    "# Later on, re-load this classifier and apply:\n",
    "new_tweets = [\"This Tweet is very shitty nasty mean and hateful\", \n",
    "            \"This is a very normal normal tweet.\", \n",
    "            \"2%^&GHJ &(&hrqjf3 click this link\"]\n",
    "\n",
    "with open(\"myvectorizer.pkl\",mode=\"rb\") as f:\n",
    "    myvectorizer = pickle.load(f)\n",
    "with open(\"myclassifier.pkl\",mode=\"rb\") as f:\n",
    "    myclassifier = joblib.load(f)\n",
    "    \n",
    "new_features = myvectorizer.transform(new_tweets)\n",
    "pred = myclassifier.predict(new_features)\n",
    "\n",
    "for tweet, label in zip(new_tweets, pred):\n",
    "    print(f\"'{tweet}' is probably '{label}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e52b18-75e5-46dc-b534-f9f14088e649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
