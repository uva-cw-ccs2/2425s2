{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12e19472",
   "metadata": {},
   "source": [
    "# Exercise: Sentiment guesser\n",
    "\n",
    "## Understanding top-down & bottom-up approaches\n",
    "\n",
    "Learning objectives\n",
    "- Understand the difference between top-down (rule-based) and bottom-up (pattern-based) approaches in sentiment analysis.\n",
    "- Implement a simple sentiment detection model using both approaches.\n",
    "- Reflect on the advantages and limitations of each method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41525fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that this exercise requires the following packages: \n",
    "#!pip3 install wordcloud matplotlib pandas numpy vaderSentiment seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7373ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13835059",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_NAME = \"GROUP AWESOME\" # change this to your group name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124ab019",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"review\": [\n",
    "    \"I absolutely love this product! It works great and is amazing.\",\n",
    "    \"This is the worst purchase I have ever made. Totally terrible!\",\n",
    "    \"It's okay, but I expected better. Not great but not bad either.\",\n",
    "    \"Fantastic quality! Exceeded my expectations.\",\n",
    "    \"I hate this so much. Worst thing ever!\",\n",
    "    \"Pretty decent, could be improved but overall not bad.\",\n",
    "    \"Superb experience! Highly recommend.\",\n",
    "    \"Disappointed. Not what I expected at all.\",\n",
    "    \"Well, it works... I guess.\",  \n",
    "    \"I was excited to try this, but it completely failed my expectations.\",  \n",
    "    \"It's a product.\"  \n",
    "]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0cd98e",
   "metadata": {},
   "source": [
    "### --- Step 1: Manual Sentiment Classification ---\n",
    "\n",
    "With your team, please discuss whether you should enter _Positive_, _Negative_, or _Neutral_ for each review.\n",
    "Please also rate your certainty for the label from 1 (very uncertain) to 5 (very certain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67985bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ManualSentiment\"] = [\"\" for _ in range(len(df))]  # Placeholder for student input\n",
    "df[\"Certainty\"] = [0 for _ in range(len(df))]  # Placeholder for certainty rating\n",
    "\n",
    "print(\"\\n### Manual Sentiment Classification ###\")\n",
    "print(\"Please manually classify the following reviews as Positive, Negative, or Neutral.\")\n",
    "print(\"Also rate your certainty from 1 (very uncertain) to 5 (very certain).\\n\")\n",
    "\n",
    "valid_sentiments = {\"Positive\", \"Negative\", \"Neutral\"}\n",
    "\n",
    "for i, review in enumerate(df[\"review\"]):\n",
    "    while True:\n",
    "        sentiment = input(f\"Review: {review}\\nYour Sentiment (Positive/Negative/Neutral): \").strip().capitalize()\n",
    "        if sentiment in valid_sentiments:\n",
    "            df.at[i, \"ManualSentiment\"] = sentiment\n",
    "            break\n",
    "        print(\"Invalid input. Please enter Positive, Negative, or Neutral.\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            certainty = int(input(\"Certainty (1-5): \"))\n",
    "            if 1 <= certainty <= 5:\n",
    "                df.at[i, \"Certainty\"] = certainty\n",
    "                break\n",
    "            else:\n",
    "                print(\"Please enter a number between 1 and 5.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a number between 1 and 5.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5b499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce9baa5",
   "metadata": {},
   "source": [
    "# --- Step 2: Top-Down Approach ---\n",
    "Use a predefined lexicon of positive and negative words. We make the following rule: \n",
    "- Positive Sentiment: If the number of positive words in the review exceeds the number of negative words, the sentiment is labeled as Positive.\n",
    "- Negative Sentiment: If the number of negative words exceeds the number of positive words, the sentiment is labeled as Negative.\n",
    "- Neutral Sentiment: If the number of positive words equals the number of negative words (or neither exceeds the other), the sentiment is labeled as Neutral.\n",
    "\n",
    "Can *you* think of additional words that should be added to the list? how does adding more words change your results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0b50e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = {\"love\", \"great\", \"excellent\", \"amazing\", \"happy\", \"fantastic\", \"superb\", \"recommend\"}\n",
    "negative_words = {\"worst\", \"terrible\", \"awful\", \"hate\", \"bad\", \"disappointed\"}\n",
    "\n",
    "def top_down_sentiment(text):\n",
    "    words = text.lower().split()\n",
    "    pos_count = sum(1 for word in words if word in positive_words)\n",
    "    neg_count = sum(1 for word in words if word in negative_words)\n",
    "    return \"Positive\" if pos_count > neg_count else \"Negative\" if neg_count > pos_count else \"Neutral\"\n",
    "\n",
    "df[\"TopDownSentiment\"] = df[\"review\"].apply(top_down_sentiment)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1dc87d",
   "metadata": {},
   "source": [
    "# --- Step 3: Bottom-up approach ---\n",
    "Use word frequency patterns to infer sentiment. \n",
    "\n",
    "The code is analyzing the frequency of words in a dataset of product reviews, based on the manually classified sentiment of each review, and visualizing the most common words using word clouds. Here's a breakdown of the operations:\n",
    "\n",
    "1. **Combining and counting words in review**:\n",
    "   - `all_words = \" \".join(df[\"review\"]).lower().split()`: \n",
    "     - This combines all reviews in the dataset into a single string (by joining them with spaces).\n",
    "     - It then converts all text to lowercase to avoid case-sensitivity.\n",
    "     - Finally, it splits the combined text into individual words.\n",
    "   - `word_counts = Counter(all_words)`: \n",
    "     - This counts the frequency of each word in the dataset using Python's `Counter` class, which creates a dictionary-like object where the keys are the words and the values are the counts.\n",
    "   \n",
    "2. **Displaying the most frequent words**:\n",
    "   - `for word, count in word_counts.most_common(20)`: \n",
    "     - This loops through the top 20 most frequent words in the dataset, where `most_common(20)` returns the 20 most frequent words and their counts.\n",
    "     - It prints each word along with its frequency.\n",
    "\n",
    "3. **Separating reviews by sentiment labels**:\n",
    "   - `positive_reviews = df[df[\"ManualSentiment\"] == 'Positive']['review']`: \n",
    "     - This creates a subset of the dataframe containing only the reviews that have been manually labeled as \"Positive\".\n",
    "   - Similarly, it creates subsets for **negative** and **neutral** reviews by filtering based on the sentiment labels (\"Negative\" and \"Neutral\").\n",
    "   \n",
    "4. **Counting words for each sentiment category**:\n",
    "   - The same process used for all reviews is repeated separately for positive, negative, and neutral reviews.\n",
    "   - `positive_words = \" \".join(positive_reviews).lower().split()`:\n",
    "     - It joins the positive reviews into one long string, converts them to lowercase, and splits them into words.\n",
    "   - `positive_word_counts = Counter(positive_words)`:\n",
    "     - It counts the frequency of words in the positive reviews using the `Counter` class.\n",
    "   - The same steps are repeated for **negative** and **neutral** reviews to count their words separately.\n",
    "\n",
    "5. **Generating word clouds**:\n",
    "   - `generate_wordcloud(word_counts, title)`: \n",
    "     - This function generates a word cloud visualization for a given set of word counts.\n",
    "     - The `WordCloud` library is used to create the cloud, and `generate_from_frequencies` takes the word counts to create the word cloud.\n",
    "     - The function then displays the word cloud using `plt.imshow()` from the `matplotlib` library.\n",
    "     - `plt.title(title, fontsize=20)` adds a title to the word cloud.\n",
    "\n",
    "6. **Displaying word clouds for each sentiment**:\n",
    "   - The code then generates and displays word clouds for **positive**, **negative**, and **neutral** words using the `generate_wordcloud` function, with each word cloud being titled appropriately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf4926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split reviews into words, convert to lowercase, and count word frequencies\n",
    "all_words = \" \".join(df[\"review\"]).lower().split()\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# Count the most frequent words in the dataset (top 20)\n",
    "print(\"Most common words in the dataset (top 20):\")\n",
    "for word, count in word_counts.most_common(20):\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "# Separate the reviews based on the sentiment labels\n",
    "positive_reviews = df[df[\"ManualSentiment\"] == 'Positive']['review']\n",
    "negative_reviews = df[df[\"ManualSentiment\"] == 'Negative']['review']\n",
    "neutral_reviews = df[df[\"ManualSentiment\"] == 'Neutral']['review']\n",
    "\n",
    "# Get the word counts for positive reviews\n",
    "positive_words = \" \".join(positive_reviews).lower().split()\n",
    "positive_word_counts = Counter(positive_words)\n",
    "\n",
    "# Get the word counts for negative reviews\n",
    "negative_words = \" \".join(negative_reviews).lower().split()\n",
    "negative_word_counts = Counter(negative_words)\n",
    "\n",
    "# Get the word counts for neutral reviews\n",
    "neutral_words = \" \".join(neutral_reviews).lower().split()\n",
    "neutral_word_counts = Counter(neutral_words)\n",
    "\n",
    "# Function to generate word clouds\n",
    "def generate_wordcloud(word_counts, title):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate_from_frequencies(word_counts)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.show()\n",
    "\n",
    "# Display word cloud for positive words\n",
    "generate_wordcloud(positive_word_counts, \"Positive words\")\n",
    "\n",
    "# Display word cloud for negative words\n",
    "generate_wordcloud(negative_word_counts, \"Negative words\")\n",
    "\n",
    "# Display word cloud for neutral words\n",
    "generate_wordcloud(neutral_word_counts, \"Neutral words\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5fb5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26beda9",
   "metadata": {},
   "source": [
    "# --- Step 4: VADER Sentiment Analysis ---\n",
    "\n",
    "In the final step, we will use a pre-trained model for sentiment classification. Since VADER relies on a predefined lexicon with sentiment scores assigned in advance, you could argue that it follows a top-down approach—applying predefined knowledge (the dictionary) to analyze new text. However, it also exhibits bottom-up characteristics because it computes the overall sentiment by aggregating individual word scores and adjusting based on syntactic rules (e.g., negation, intensifiers, punctuation).\n",
    "\n",
    "So, it’s a bit of both:\n",
    "- Top-down because it starts with a pre-built sentiment dictionary.\n",
    "- Bottom-up because it builds sentiment from individual words and adjusts based on context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bd64b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_sentiment(text):\n",
    "    score = analyzer.polarity_scores(text)\n",
    "    return \"Positive\" if score[\"compound\"] > 0.05 else \"Negative\" if score[\"compound\"] < -0.05 else \"Neutral\"\n",
    "\n",
    "df[\"VADER_Sentiment\"] = df[\"review\"].apply(vader_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2040715",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c582e6ff",
   "metadata": {},
   "source": [
    "# --- Step 5: Agreement calculation  ---\n",
    "\n",
    "What does this tell us about agreement with human annotations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d55fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agreement_score(manual, predicted):\n",
    "    return 1 if manual == predicted else 0\n",
    "\n",
    "# apply the agreement score calculation\n",
    "df[\"agreement_topdown\"] = df.apply(lambda row: agreement_score(row[\"ManualSentiment\"], row[\"TopDownSentiment\"]), axis=1)\n",
    "df[\"agreement_vader\"] = df.apply(lambda row: agreement_score(row[\"ManualSentiment\"], row[\"VADER_Sentiment\"]), axis=1)\n",
    "\n",
    "# calculate non-weighted agreement percentages\n",
    "def non_weighted_agreement(agreement_col):\n",
    "    return df[agreement_col].mean()\n",
    "\n",
    "agreement_summary = {\n",
    "    \"top-down agreement\": non_weighted_agreement(\"agreement_topdown\"),\n",
    "    \"vader agreement\": non_weighted_agreement(\"agreement_vader\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa84ddd5",
   "metadata": {},
   "source": [
    "# --- Step 6: visualization of agreement scores ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52d329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "agreement_df = pd.DataFrame(list(agreement_summary.items()), columns=[\"SentimentMethod\", \"AgreementScore\"])\n",
    "\n",
    "# Plot agreement scores using Seaborn\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=\"SentimentMethod\", y=\"AgreementScore\", data=agreement_df, palette=\"Set2\")\n",
    "\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"Sentiment analysis method\")\n",
    "plt.ylabel(\"Agreement Score\")\n",
    "plt.title(f\"Agreement between manual annotations and automated methods {GROUP_NAME}\")\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(f\"agreement_scores_{GROUP_NAME}.png\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9d3e2d",
   "metadata": {},
   "source": [
    "## FINAL: Show me the results!\n",
    "Upload your final result: [here](https://amsuni-my.sharepoint.com/:f:/g/personal/a_c_kroon_uva_nl/EitpVGH7CXtKlnzRCye9zOoB5Fu-mIgISaA8IANncePrEQ?e=CQV5wX)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
