{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12e19472",
   "metadata": {},
   "source": [
    "# Exercise: -- Sentiment Guesser –-\n",
    "\n",
    "## Understanding Top-down & Bottom-up Approaches\n",
    "\n",
    "Learning objectives\n",
    "- Understand the difference between top-down (rule-based) and bottom-up (pattern-based) approaches in sentiment analysis.\n",
    "- Implement a simple sentiment detection model using both approaches.\n",
    "- Reflect on the advantages and limitations of each method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124ab019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "data = {\"review\": [\n",
    "    \"I absolutely love this product! It works great and is amazing.\",\n",
    "    \"This is the worst purchase I have ever made. Totally terrible!\",\n",
    "    \"It's okay, but I expected better. Not great but not bad either.\",\n",
    "    \"Fantastic quality! Exceeded my expectations.\",\n",
    "    \"I hate this so much. Worst thing ever!\",\n",
    "    \"Pretty decent, could be improved but overall not bad.\",\n",
    "    \"Superb experience! Highly recommend.\",\n",
    "    \"Disappointed. Not what I expected at all.\",\n",
    "    \"Well, it works... I guess.\",  \n",
    "    \"I was excited to try this, but it completely failed my expectations.\",  \n",
    "    \"It's a product.\"  \n",
    "]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0cd98e",
   "metadata": {},
   "source": [
    "### --- Step 1: Manual Sentiment Classification ---\n",
    "\n",
    "With your team, please discuss whether you should enter _Positive_, _Negative_, or _Neutral_ for each review.\n",
    "Please also rate your certainty for the label from 1 (very uncertain) to 5 (very certain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67985bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ManualSentiment\"] = [\"\" for _ in range(len(df))]  # Placeholder for student input\n",
    "df[\"Certainty\"] = [0 for _ in range(len(df))]  # Placeholder for certainty rating\n",
    "\n",
    "print(\"\\n### Manual Sentiment Classification ###\")\n",
    "print(\"Please manually classify the following reviews as Positive, Negative, or Neutral.\")\n",
    "print(\"Also rate your certainty from 1 (very uncertain) to 5 (very certain).\\n\")\n",
    "\n",
    "valid_sentiments = {\"Positive\", \"Negative\", \"Neutral\"}\n",
    "\n",
    "for i, review in enumerate(df[\"review\"]):\n",
    "    while True:\n",
    "        sentiment = input(f\"Review: {review}\\nYour Sentiment (Positive/Negative/Neutral): \").strip().capitalize()\n",
    "        if sentiment in valid_sentiments:\n",
    "            df.at[i, \"ManualSentiment\"] = sentiment\n",
    "            break\n",
    "        print(\"Invalid input. Please enter Positive, Negative, or Neutral.\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            certainty = int(input(\"Certainty (1-5): \"))\n",
    "            if 1 <= certainty <= 5:\n",
    "                df.at[i, \"Certainty\"] = certainty\n",
    "                break\n",
    "            else:\n",
    "                print(\"Please enter a number between 1 and 5.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a number between 1 and 5.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5b499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce9baa5",
   "metadata": {},
   "source": [
    "# --- Step 2: Top-Down Approach ---\n",
    "Use a predefined lexicon of positive and negative words. Can you think of additional words that should be added to the list? how does adding more words change your results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0b50e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = {\"love\", \"great\", \"excellent\", \"amazing\", \"happy\", \"fantastic\", \"superb\", \"recommend\"}\n",
    "negative_words = {\"worst\", \"terrible\", \"awful\", \"hate\", \"bad\", \"disappointed\"}\n",
    "\n",
    "def top_down_sentiment(text):\n",
    "    words = text.lower().split()\n",
    "    pos_count = sum(1 for word in words if word in positive_words)\n",
    "    neg_count = sum(1 for word in words if word in negative_words)\n",
    "    return \"Positive\" if pos_count > neg_count else \"Negative\" if neg_count > pos_count else \"Neutral\"\n",
    "\n",
    "df[\"TopDownSentiment\"] = df[\"review\"].apply(top_down_sentiment)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1dc87d",
   "metadata": {},
   "source": [
    "# --- Step 3: Bottom-Up Approach ---\n",
    "Use word frequency patterns to infer sentiment. Start by displaying the most common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf4926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split reviews into words, convert to lowercase, and count word frequencies\n",
    "all_words = \" \".join(df[\"review\"]).lower().split()\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "\n",
    "print(\"Most common words in the dataset (top 20):\")\n",
    "for word, count in word_counts.most_common(20):\n",
    "    print(f\"{word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395a0f9d",
   "metadata": {},
   "source": [
    "Based on the output above, please insert the most common positive and negative words in the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effaf7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input common positive words\n",
    "print(\"\\nPlease input common positive words based on the frequency analysis\")\n",
    "positive_input = input(\"Enter positive words (comma-separated): \")\n",
    "common_positive = set(positive_input.lower().split(','))\n",
    "\n",
    "# Input common negative words\n",
    "print(\"\\nPlease input common negative words based on the frequency analysis (e.g., worst, bad, terrible).\")\n",
    "negative_input = input(\"Enter negative words (comma-separated): \")\n",
    "common_negative = set(negative_input.lower().split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee88bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bottom_up_sentiment(text):\n",
    "    words = text.lower().split()\n",
    "    pos_count = sum(1 for word in words if word in common_positive)\n",
    "    neg_count = sum(1 for word in words if word in common_negative)\n",
    "    return \"Positive\" if pos_count > neg_count else \"Negative\" if neg_count > pos_count else \"Neutral\"\n",
    "\n",
    "df[\"BottomUpSentiment\"] = df[\"review\"].apply(bottom_up_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5fb5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26beda9",
   "metadata": {},
   "source": [
    "# --- Step 4: VADER Sentiment Analysis ---\n",
    "\n",
    "In the final step, we will use a pre-trained model for sentiment classification. Since VADER relies on a predefined lexicon with sentiment scores assigned in advance, you could argue that it follows a top-down approach—applying predefined knowledge (the dictionary) to analyze new text. However, it also exhibits bottom-up characteristics because it computes the overall sentiment by aggregating individual word scores and adjusting based on syntactic rules (e.g., negation, intensifiers, punctuation).\n",
    "\n",
    "So, it’s a bit of both:\n",
    "- Top-down because it starts with a pre-built sentiment dictionary.\n",
    "- Bottom-up because it builds sentiment from individual words and adjusts based on context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bd64b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_sentiment(text):\n",
    "    score = analyzer.polarity_scores(text)\n",
    "    return \"Positive\" if score[\"compound\"] > 0.05 else \"Negative\" if score[\"compound\"] < -0.05 else \"Neutral\"\n",
    "\n",
    "df[\"VADER_Sentiment\"] = df[\"review\"].apply(vader_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2040715",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c582e6ff",
   "metadata": {},
   "source": [
    "# --- Step 5: Agreement calculation  ---\n",
    "\n",
    "what methods renders the highest agreement with human annotations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d55fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agreement_score(manual, predicted):\n",
    "    return 1 if manual == predicted else 0\n",
    "\n",
    "# apply the agreement score calculation\n",
    "df[\"agreement_topdown\"] = df.apply(lambda row: agreement_score(row[\"ManualSentiment\"], row[\"TopDownSentiment\"]), axis=1)\n",
    "df[\"agreement_bottomup\"] = df.apply(lambda row: agreement_score(row[\"ManualSentiment\"], row[\"BottomUpSentiment\"]), axis=1)\n",
    "df[\"agreement_vader\"] = df.apply(lambda row: agreement_score(row[\"ManualSentiment\"], row[\"VADER_Sentiment\"]), axis=1)\n",
    "\n",
    "# calculate non-weighted agreement percentages\n",
    "def non_weighted_agreement(agreement_col):\n",
    "    return df[agreement_col].mean()\n",
    "\n",
    "agreement_summary = {\n",
    "    \"top-down agreement\": non_weighted_agreement(\"agreement_topdown\"),\n",
    "    \"bottom-up agreement\": non_weighted_agreement(\"agreement_bottomup\"),\n",
    "    \"vader agreement\": non_weighted_agreement(\"agreement_vader\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa84ddd5",
   "metadata": {},
   "source": [
    "# --- step 6: visualization of agreement scores ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52d329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n### final sentiment analysis results ###\\n\", df[[\"review\", \"ManualSentiment\", \"Certainty\", \"TopDownSentiment\", \"BottomUpSentiment\", \"VADER_Sentiment\"]])\n",
    "print(\"\\n### non-weighted agreement scores ###\\n\", agreement_summary)\n",
    "\n",
    "# plot agreement scores\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(agreement_summary.keys(), agreement_summary.values(), color=['blue', 'green', 'red'])\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"sentiment analysis method\")\n",
    "plt.ylabel(\"agreement score\")\n",
    "plt.title(\"agreement between manual annotations and automated methods\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
